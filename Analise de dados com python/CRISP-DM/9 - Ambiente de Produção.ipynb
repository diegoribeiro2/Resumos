{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q4mXX8U3Fky"
      },
      "source": [
        "#Matéria 04 - Análise de Regressão em Python pt 04 b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMqMSyi1Uj-H"
      },
      "source": [
        "### 335 Boas Vindas ao Módulo - Murilo Mendonça\n",
        "<h1>Deployment de modelos de Machine Learning</h1><h2>Introdução</h2><ul><li>Ambiente de produção<ul><li>Conceitos importantes para entender o deployment</li></ul></li></ul><h2>Planejamento do deployment</h2><ul><li>Modelos em batch<ul><li>Lotes de predição</li><li>O que considerar na entrega de modelos batch</li></ul></li><li>Modelos como API<ul><li>Complexidades adicionais</li><li>Diferenças para deploy de modelos batch</li></ul></li></ul><h2>Monitoramento</h2><ul><li>Performance do modelo<ul><li>Precisão, vieses</li><li>Satisfação do usuário final</li></ul></li><li>Planejar antes da entrega ao negócio</li></ul><h2>Manutenção</h2><ul><li>Modelos precisam de retreinamento<ul><li>Ajustes e novas versões</li><li>Exemplo: impacto da COVID-19</li></ul></li><li>Etapas para entregar uma nova versão</li></ul><h2>Relatório final</h2><ul><li>Documentar todo o processo CRISP-DM</li><li>Apresentação para o negócio<ul><li>Explicar valor entregue</li><li>Técnicas de apresentação</li></ul></li></ul><p>O vídeo cobre os principais tópicos relacionados ao deployment de modelos de Machine Learning, desde o planejamento em diferentes ambientes (batch e API), passando pelo monitoramento e manutenção, até a documentação final e apresentação para o negócio.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpI4TBDWUmFv"
      },
      "source": [
        "### 336 Ambiente de Produção\n",
        "<p>TEMA CENTRAL: Ambiente de produção em ciência de dados</p><ul><li><p>Definição de ambiente de produção</p><ul><li>Onde o usuário interage com o modelo/produto</li><li>Separado do ambiente de desenvolvimento</li><li>Permite controle de versão e deploy faseado</li></ul></li><li><p>Testes</p><ul><li>Unitários: testam unidades isoladas de código</li><li>Integrados: testam integração entre funções e elementos externos</li></ul></li><li><p>Serialização de modelos</p><ul><li>Permite salvar estado do modelo treinado</li><li>Técnicas: pickle, cloudpickle, joblib, MLflow</li><li>Armazenamento:<ul><li>File system (não recomendado)</li><li>Cloud storage</li><li>Dentro de imagem Docker</li><li>Banco de dados (possível mas não usual)</li></ul></li></ul></li><li><p>Próximos passos</p><ul><li>Planejar deployment do modelo em produção</li></ul></li></ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx_0q_dFUn4t"
      },
      "source": [
        "### 337 Planejando o Deployment (Batch)\n",
        "<h1>Planejando o Deployment para Batch</h1><h2>Tema central</h2><p>Como planejar e preparar a entrega de modelos de machine learning em lotes (batch) para produção.</p><h2>Tópicos abordados</h2><h3>Pipelines de dados</h3><ul><li>Similaridade entre pipelines de ETL (engenharia de dados) e pipelines de machine learning<ul><li>Ambos seguem passos de extrair, transformar e carregar dados (ETL)</li></ul></li><li>Importância de pensar na entrega como um &quot;pipeline&quot; fim-a-fim</li></ul><h3>Spark e MLflow</h3><ul><li>Spark: ferramenta para processamento distribuído e paralelo de grandes quantidades de dados<ul><li>Permite definir pipelines como &quot;jobs&quot;</li></ul></li><li>MLflow: ferramenta para gerenciamento do ciclo de vida de modelos<ul><li>Permite carregar modelos treinados em pipelines Spark para predições em larga escala</li></ul></li><li>Integração entre Spark e MLflow traz ganhos de performance e prepara pipelines para crescimento futuro</li></ul><h3>Periodicidade e orquestração</h3><ul><li>Periodicidade: com que frequência o pipeline de predições precisa ser executado</li><li>Orquestração: como conectar e agendar a execução das etapas do pipeline<ul><li>Opções:<ul><li>Via código</li><li>Ferramentas de agendamento de tarefas</li><li>Ferramentas de orquestração (Airflow, Prefect etc)<ul><li>Apenas orquestram, não processam dados (precisam chamar Spark, por exemplo)</li></ul></li></ul></li></ul></li></ul><h2>Considerações finais</h2><ul><li>Planejar a entrega dos modelos como pipelines fim-a-fim é essencial</li><li>Permite preparar infrastructure para escalar conforme necessário</li><li>Garante que os modelos entreguem valor ao negócio de forma recorrente</li></ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuVQDiJvUqJd"
      },
      "source": [
        "### 338 Planejando o Deployment (API)\n",
        "<h1>Tema central:</h1><p>Planejamento do deployment de uma API de Machine Learning</p><h2>O que é uma API</h2><ul><li>Analogia com pedir comida em um restaurante</li><li>Interface para fazer requisições e obter resultados/predições</li><li>Exemplo: modelo de predição com features de entrada e predições como saída</li></ul><h2>Complexidade de uma API vs Batch</h2><ul><li>Intermitência e disponibilidade</li><li>Necessidade de contrato bem definido</li><li>Importância da documentação</li><li>Autenticação e segurança</li><li>Infraestrutura escalável</li><li>Performance aceitável para o usuário</li></ul><h2>Mini Batches</h2><ul><li>A API ainda segue uma sequência de passos (ETL + predições)</li><li>Possibilidade de desacoplar preparação de features para melhorar performance</li></ul><h2>Ambientes de execução</h2><ul><li>Máquina virtual</li><li>Serviços gerenciados (SageMaker, Azure ML etc)</li><li>Serverless (AWS Lambda, Azure Functions etc)</li><li>Container instances</li><li>Kubernetes</li></ul><h2>Métricas</h2><h3>Aplicação</h3><ul><li>Latência</li><li>Tráfego</li><li>Erros</li><li>Saturação</li></ul><h3>Machine Learning</h3><ul><li>Métricas de performance do modelo</li><li>Qualidade dos dados de entrada</li><li>ROI e impacto no negócio</li></ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlI6WPQXUrrd"
      },
      "source": [
        "### 339 Planejando o Monitoramento do Modelo\n",
        "<h2>Tema central: Planejamento do monitoramento de modelos de machine learning</h2><h3>Métricas de machine learning</h3><ul><li>Acompanhar se modelo está acertando predições</li><li>Em modelos batch:<ul><li>Criar DAG de métricas para comparar predições com dados reais</li><li>Plugar resultados em dashboard para monitoramento em tempo real</li></ul></li><li>Em APIs:<ul><li>Persistir todas predições no banco de dados</li><li>Fazer análise retroativa comparando com valores reais</li><li>Construir DAG de métricas para cheque de sanidade periódico</li></ul></li></ul><h3>Métricas de aplicação</h3><ul><li>4 sinais dourados para observabilidade de aplicações:<ul><li>Latência</li><li>Tráfego</li><li>Erros</li><li>Saturação</li></ul></li><li>Latência:<ul><li>Tempo de resposta da requisição</li><li>Definir políticas de timeout</li></ul></li><li>Tráfego:<ul><li>Número de requisições</li><li>Requisições por segundo</li><li>Respostas das requisições (200 OK, 400 Erro, 500 Erro Servidor)</li></ul></li><li>Saturação:<ul><li>Uso de CPU</li><li>Uso de memória</li><li>Pods disponíveis</li><li>Máquinas disponíveis</li></ul></li></ul><h3>Ferramentas de monitoramento</h3><ul><li>Datadog, Grafana, Honeycomb</li><li>Integrações com diversas aplicações</li><li>Aplicativos dos provedores de cloud: Azure Application Insights</li><li>Scrapers: Prometheus, StatsD</li></ul><h3>Caso real: problema de vazamento de memória</h3><ul><li>Após atualização, aplicação começou a consumir muita memória</li><li>Monitoramento permitiu identificar e corrigir problema rapidamente</li><li>Garantiu disponibilidade e entrega de valor ao cliente</li></ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gahlTmvIo5UA"
      },
      "source": [
        "## Planejando Manutenções do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHVLBgIsVHGW"
      },
      "source": [
        "### 340 Planejando Manutenções do Modelo\n",
        "<h1>Planejamento de Manutenção</h1><h2>Tipos de Manutenção</h2><ul><li>Programada<ul><li>Ex: atualizar modelo de série temporal semanalmente</li></ul></li><li>Não programada<ul><li>Ex: quando o negócio percebe um problema</li><li>Ex: quando recebe um alerta do monitoramento</li></ul></li></ul><h2>Repositório</h2><ul><li>Ajuda a controlar versões do código</li><li>Estrutura<ul><li>Análises (notebooks)</li><li>Dados (referências)</li><li>Documentação</li><li>Logs</li><li>Código fonte</li><li>Testes</li></ul></li></ul><h2>CICD</h2><ul><li>Integração Contínua<ul><li>Testes automatizados ao fazer um commit</li></ul></li><li>Deploy Contínuo<ul><li>Levar versão testada para produção</li></ul></li></ul><p>O vídeo aborda boas práticas para planejar a manutenção de modelos de machine learning, mantendo o controle de versões e qualidade por meio de repositórios, integração e deploy contínuos.</p>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
