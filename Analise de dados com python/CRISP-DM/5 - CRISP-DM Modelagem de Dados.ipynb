{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38HRUrReSiB9"
      },
      "source": [
        "## **Módulo Matéria 04** - Análise de Regressão em Python Parte 03 Crisp-DM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoDsR-rknQi2"
      },
      "source": [
        "## CRISP-DM: Modelagem de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA3PP19Ul4p-"
      },
      "source": [
        "### 316 Definindo Modeling\n",
        "###### Data preparation 60 a 70% do projeto\n",
        "###### Construção do modelo\n",
        "###### Calibrar os parametros (hyperparameters)\n",
        "###### Avaliar o modelo, visão técnica\n",
        "###### Data mining Goal\n",
        "###### Variável\n",
        "###### Clusterização\n",
        "<h1>Tema central: Fase de Modeling no CRISP-DM</h1><h2>Select Modeling Technique</h2><ul><li>Tarefa de selecionar as técnicas de modelagem que serão utilizadas</li><li>Output:<ul><li>Modeling Technique (técnica de modelagem)</li><li>Modeling Assumptions (premissas da modelagem)</li></ul></li></ul><h2>Generate Test Design</h2><ul><li>Tarefa de gerar o design de teste</li><li>Output:<ul><li>Test Design (design de teste)</li></ul></li></ul><h2>Build Model</h2><ul><li>Fase onde o modelo é efetivamente construído</li></ul><h2>Assess Model</h2><ul><li>Tarefa de avaliar o desempenho do modelo</li></ul><h2>Hiperparâmetros</h2><ul><li>Parâmetros que controlam o aprendizado do modelo</li><li>Exemplos:<ul><li>Número de grupos no k-means</li><li>Normalizar dados</li><li>Quantidade de épocas em redes neurais</li></ul></li><li>São ajustados na fase de Modeling para melhorar o desempenho</li></ul><h2>Importância da fase Modeling</h2><ul><li>Não é a fase mais longa nem trabalhosa</li><li>Representa apenas 2-3 linhas de código às vezes</li><li>Data Understanding e Data Preparation consomem mais tempo (60-70%)</li></ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV6jJZiTl4in"
      },
      "source": [
        "### 317 Selection Modeling Technique\n",
        "###### Seleção da técnica do modelo\n",
        "###### Técnica de modelagem específica\n",
        "###### Várias técnicas forem aplicadas, execute esta tarefa separadamente para cada técnica\n",
        "###### Types of Regression\n",
        "###### Linear Regression\n",
        "###### Polynomial Regression\n",
        "###### Support Vector Regression\n",
        "###### Decision tree Regression\n",
        "###### Random Forest Regression\n",
        "###### Ridge Regression\n",
        "###### Lasso Regression\n",
        "###### Logistic Regression\n",
        "###### Output\n",
        "###### Modeling Technique\n",
        "###### Documentar a técnica que foi selecionada\n",
        "###### Modeling Assumptions - Descrever essas premissas técnicas\n",
        "###### Premissas da técnica selecionada\n",
        "<h1>Seleção de Técnicas de Modelagem</h1><h2>O que é essa tarefa</h2><ul><li>Tarefa de selecionar a(s) técnica(s) de modelagem que será(ão) utilizada(s)</li><li>Deve-se escolher técnicas específicas (ex: KNN, árvore de decisão) e não apenas o tipo (ex: classificação)</li><li>Se forem escolhidas várias técnicas, a tarefa deve ser executada separadamente para cada uma</li></ul><h2>Saídas</h2><h3>Modeling Technique</h3><ul><li>Documentar qual(is) técnica(s) foi(ram) escolhida(s)</li><li>Ex: regressão linear simples do Scikit-Learn</li></ul><h3>Modeling Assumptions</h3><ul><li>Descrever premissas e limitações técnicas da(s) técnica(s) escolhida(s)</li><li>Ex: modelo não aceita valores categóricos (requer one-hot encoding)</li></ul><h2>Como fazer a seleção</h2><ul><li>Pesquisar técnicas mais utilizadas para o caso de uso</li><li>Testar 3-4 técnicas diferentes</li><li>Escolher técnicas similares para permitir comparação na avaliação</li><li>Ex: vários tipos de regressão ou vários tipos de clusterização</li></ul>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZW3YqqOl4Te"
      },
      "source": [
        "### 318 Generate Test Design\n",
        "###### Construção do teste do modelo\n",
        "###### Teste intríseco (interno) do próprio modelo\n",
        "###### Analisar R Square ou F1- Score\n",
        "###### Como irá separar os dados para o modelo\n",
        "###### Train/Test\n",
        "###### Iteration 1 Test/Train/Train/Train/Train\n",
        "###### Cross Validation\n",
        "###### Test/Train/Train/Train/Train\n",
        "###### Train/Test/Train/Train/Train\n",
        "###### Train/Train/Test/Train/Train\n",
        "###### Train/Train/Train/Test/Train\n",
        "###### Métrica a ser avaliada\n",
        "###### Accuracy = TruePositive + TrueNegative / TotalSample\n",
        "###### F1 = 2 x Precision * Recall / Precision + Recall\n",
        "###### Output\n",
        "###### Qual o plano de treinamento, o teste e a validação que será implementada\n",
        "###### Ponto importante\n",
        "###### Como dataset será dividido em train, test e validation set\n",
        "<h2>Tema central: Generate Test Design</h2><p>Essa tarefa consiste em:</p><ul><li>Gerar o design de testes para avaliar o modelo</li><li>Definir o método de teste intrínseco (teste interno focado no modelo)</li></ul><h3>Métricas</h3><ul><li>Definir métricas para avaliar o modelo<ul><li>Exemplos: R-square, F1-score</li></ul></li><li>Métricas dependem do tipo de modelo<ul><li>Regressão vs classificação</li></ul></li></ul><h3>Separação de dados</h3><ul><li>Definir como separar os dados em conjunto de treino e teste</li><li>Opções:<ul><li>Simples split treino/teste</li><li>Cross-validation</li><li>Percentual de exemplos de cada tipo no conjunto de teste</li><li>Baseado em tempo (últimos X meses no conjunto de teste)</li></ul></li></ul><h3>Saída</h3><ul><li>Test design:<ul><li>Plano de treino e teste</li><li>Como será feita a separação</li><li>Métricas usadas para validação</li><li>Não entra em detalhes técnicos</li></ul></li></ul><p>O foco é determinar como separar os dados e definir métricas de avaliação.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY2yRvEHl3xe"
      },
      "source": [
        "### 319 Build Model\n",
        "###### Executar as ferramentas de modelagem sobre o teu dataset preparado\n",
        "###### Construção do seu modelo\n",
        "###### 1 a 3 linhas\n",
        "###### Output\n",
        "###### **Parameters Settings** - Configuração\n",
        "###### Série de hyperparâmetros definidos no modelo\n",
        "###### lista de parametros definidos e o valor deles\n",
        "###### **Model & Model Description**\n",
        "###### O próprio modelo é um output\n",
        "###### Descrição desse modelo, utilização e documentação\n",
        "<h1>Construção de Modelos</h1><h2>Introdução</h2><ul><li>Etapa após a seleção da técnica de modelagem e preparação dos dados</li><li>Consiste em executar as ferramentas de modelagem no dataset preparado</li><li>Geralmente são poucas linhas de código</li><li>Exemplos:<ul><li>Uso de funções como LinearRegression() do scikit-learn</li><li>Ferramentas de modelagem com interface clicável</li></ul></li></ul><h2>Outputs</h2><ul><li>Parameter Settings<ul><li>Configurações dos hiperparâmetros de cada modelo</li><li>Pode ser documentado comentando no código quais parâmetros foram alterados</li></ul></li><li>Model<ul><li>O modelo treinado em si, pronto para fazer predições</li><li>No exemplo, a variável &quot;reg&quot;</li></ul></li><li>Model Description<ul><li>Documentação básica sobre o modelo</li><li>Pode ser apenas uma referência à documentação da biblioteca usada</li></ul></li></ul><h2>Considerações Finais</h2><ul><li>Etapa rápida, porém importante após todo o trabalho de preparação de dados</li><li>Não precisa de documentação muito robusta, mas ter os outputs facilita a organização</li><li>O modelo estará pronto para avaliação e uso em produção</li></ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj1S1BFuasew"
      },
      "source": [
        "### 320 Assess Model\n",
        "###### Avaliação do modelo\n",
        "###### De acordo: Critérios de sucesso de mineração de dados e design de testes\n",
        "###### Avaliação de apenas do modelo\n",
        "###### Evaluation avaliação do todo\n",
        "###### Avaliação das técnicas diferentes e dos modelos\n",
        "###### Output\n",
        "###### **Model Assessment**\n",
        "###### Sumarização com o resultado da analise\n",
        "###### **Revised Parameter Settings**\n",
        "###### Revisar os hyperparametros do modelo e realizar ajustes e buildar novamente\n",
        "###### Até encontrar o melhor modelo\n",
        "<h1>Avaliação de Modelos de Machine Learning</h1><h2>Introdução</h2><ul><li>Última tarefa da etapa de modelagem</li><li>Vamos avaliar os modelos de acordo com:<ul><li>Critérios de sucesso definidos na fase de entendimento do negócio</li><li>Métricas definidas no teste de design</li></ul></li></ul><h2>Tarefas</h2><ul><li>Avaliar o desempenho dos modelos<ul><li>Ex: Modelo XGBoost teve melhor acurácia que regressão linear</li></ul></li><li>Escolher o melhor modelo para seguir para a próxima fase</li></ul><h2>Outputs</h2><ul><li>Model Assessment<ul><li>Documentar a avaliação no código<ul><li>Explicar por que um modelo foi escolhido</li></ul></li><li>Verificar se atende os critérios iniciais</li></ul></li><li>Revised Parameter Settings<ul><li>Otimizar hiperparâmetros<ul><li>Melhorar assertividade do modelo</li></ul></li><li>Técnicas específicas para cada tipo de modelo</li></ul></li></ul><h2>Considerações Finais</h2><ul><li>Avaliação focada apenas nos modelos</li><li>Próxima fase terá avaliação mais ampla</li></ul>\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
